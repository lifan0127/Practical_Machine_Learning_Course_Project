qt(.975, 8)
qt(.975,18)
qt(.95, 16)
qt(.95, 8)
?qt
qt(.975, 8)
pooledVariance <- function(v, n, sq.root = FALSE){
res <- sum((n-1)*v)/(sum(n) - 2)
if (sq.root) {
return(sqrt(res))
}
return(res)
}
confintPool <- function(m, v, n){
spool <- pooledVariance(v, n, T)
res <- m + c(-1, 1)*spool*qt(0.975, sum(n)-2)*sqrt(sum(1/n))
return(res)
}
qt(.975, 16)
2*sqrt(18)/qt(.975, 16)
qt(.975, 8)
2*3/qt(.975, 8)
2*3/qt(.975, 8)
nstall.packages("shiny")
install.packages("shiny")
library(shiny)
sample.mean <- 1100
sample.size <- 9
sample.sd <- 30
error <- qt(0.975, df=sample.size-1)*sample.sd/sqrt(sample.size)
error
sample.mean + error
sample.mean - error
?t.test
qt(0.95, df=8)
sample.sd <- -2/qt(0.95, df=8)*sqrt(9)
sample.sd
2/1.859548*3
2/qt(0.975, df=8)*sqrt(9)
sample.sd <- -2/qt(0.975, df=8)*sqrt(9)
sample.sd
t <- (3-5)/sqrt(0.6^2/10+0.68^2/10)
t
?t.test
v <- (0.6^2/10+0.68^2/10)^2/((0.6^2/10)^2/9+(0.68^2/10)^2/9)
v
qt(0.975, v)
qt(0.975, 17)
v <- (0.6/10+0.68/10)^2/((0.6/10)^2/9+(0.68/10)^2/9)
v
qt(0.975, v)
(0.6/10+0.68/10)^2/((0.6/10)^2/9+(0.68/10)^2/9)
(0.6^2/10+0.68^2/10)^2/((0.6^2/10)^2/9+(0.68^2/10)^2/9)
v <- (0.6/10+0.68/10)^2/((0.6/10)^2/9+(0.68/10)^2/9)
v
qt(0.975, v)
error <- qt(0.975, v)*sqrt(12.8/20)/sqrt(20)
error
a <- rnorm(100)
a
hist(a)
qqplot(a, a)
b <- rexp(100)
qqplot(a, b)
a <- rnorm(1000)
b <- rexp(1000)
qqplot(a, b)
qqplot(b, a)
plot(seq(0, 8, 0.1), (1-exp(sep(0, 8, 0.1))))
plot(seq(0, 8, 0.1), (1-exp(seq(0, 8, 0.1))))
plot(seq(0, 8, 0.1), (-log(seq(0, 8, 0.1))))
plot(seq(0, 8, 0.1), -(-log(seq(0, 8, 0.1))))
qqplot(a, 4*a+1)
?predict
?lm
?d1gamma
?dgamma
?getClass
?showMethod
?showMethods
?getMethod
install.packages("binom")
library(binom)
?binom.bayes
14/30
lognorma(5, 1)
rlnorm(5, 1)
rlnorm(10, 5, 1)
exp(mean(log(rlnorm(10, 5, 1))))
exp(mean(log(rlnorm(100, 5, 1))))
exp(mean(log(rlnorm(1000, 5, 1))))
exp(mean(log(rlnorm(1000, 5, 1))))
exp(mean(log(rlnorm(10000, 5, 1))))
exp(mean(log(rlnorm(100000, 5, 1))))
exp(mean(log(rlnorm(1000000, 5, 1))))
exp(mean(log(rlnorm(10000000, 5, 1))))
exp(5)
exp(5.5)
mean(log(rlnorm(10000000, 5, 1)))
mean(rlnorm(10000000, 5, 1))
install.packages("Rcpp")
library(Rcpp)
library(devtools)
install.github("fastread", "hadley")
install_github("fastread", "hadley")
library(knitr)
library(ggplot2)
library(dplyr)
library(caret)
library(randomForest)
setwd("C:/Users/Fan/R/Kaggle/Forest Cover Type Prediction")
options(stringsAsFactors=FALSE)
train <- tbl_df(read.csv("train.csv", stringsAsFactors=FALSE))
test <- tbl_df(read.csv("test.csv", stringsAsFactors=FALSE))
train[, 12:55] <- lapply(train[, 12:55], factor)
#table(train$Cover_Type)  # 2160 each type
train[, "Soil_Type7"] <- train[, "Soil_Type15"] <- NULL
train <- tbl_df(read.csv("train.csv", stringsAsFactors=FALSE))
train.tmp <- melt(train[, -1], id="Cover_Type")
library(reshape2)
train.tmp <- melt(train[, -1], id="Cover_Type")
ggplot(train.tmp, aes(x=variable, y=Cover_Type)) + geom_point()
ggplot(train.tmp, aes(x=value, y=Cover_Type)) +
geom_point() +
facet_wrap(~variable, ncol=6)
ggplot(train.tmp, aes(x=value, y=Cover_Type)) +
geom_point() +
facet_wrap(~variable, ncol=8)
dim(train)
for(i in 2:55){
p <- ggplot(train, aes_string(x=colnames(train)[i], y="Cover_Type")) +
geom_point()
print(p)
}
train[, 12:55] <- lapply(train[, 12:55], factor)
train[, "Soil_Type7"] <- train[, "Soil_Type15"] <- NULL
str(train)
dim(train)
model.rf <- train(train[, 2:53], data=train[, 54], method="rf")
model.rf <- train(Cover_Type~., data=train[, -1], method="rf")
train <- tbl_df(read.csv("train.csv", stringsAsFactors=FALSE))
test <- tbl_df(read.csv("test.csv", stringsAsFactors=FALSE))
train[, 12:55] <- lapply(train[, 12:55], factor)
dim(train)
train <- tbl_df(read.csv("train.csv", stringsAsFactors=FALSE))
train[, 12:55] <- lapply(train[, 12:56], factor)
train <- tbl_df(read.csv("train.csv", stringsAsFactors=FALSE))
train[, 12:56] <- lapply(train[, 12:56], factor)
train[, "Soil_Type7"] <- train[, "Soil_Type15"] <- NULL
small.train <- createDataPartition(train$Cover_Type, p=0.1, list=FALSE)
model.rf <- train(Cover_Type~., data=train[small.train, -1], method="rf")
install.packages("e1071")
model.rf <- train(Cover_Type~., data=train[small.train, -1], method="rf")
predict.rf <- predict(model.rf, newdata=test[, -1])
test[, 12:56] <- lapply(test[, 12:56], factor)
test <- tbl_df(read.csv("test.csv", stringsAsFactors=FALSE))
test[, 12:55] <- lapply(test[, 12:55], factor)
test[, "Soil_Type7"] <- test[, "Soil_Type15"] <- NULL
predict.rf <- predict(model.rf, newdata=test[, -1])
write.csv(cbind(test[1], predict.rf), "submission01.csv", row.names=FALSE)
write.csv(Id=cbind(test[1], Cover_Type=predict.rf), "submission01.csv", row.names=FALSE)
write.csv(cbind(Id=test[1], Cover_Type=predict.rf), "submission01.csv", row.names=FALSE)
install.packages("C50")
library(C50)
model.C50 <- train(Cover_Type~., data=train[small.train, -1], method="C50")
library(C50)
model.C50 <- train(Cover_Type~., data=train[small.train, -1], method="C50")
model.C50 <- train(Cover_Type~., data=train[small.train, -1], method="C50")
model.C50 <- train(Cover_Type~., data=train[small.train, -1], method="C5.0")
predict.C50 <- predict(model.C50, newdata=test[, -1])
write.csv(cbind(Id=test[1], Cover_Type=predict.C50), "submission02_C50.csv", row.names=FALSE)
small.train2 <- createDataPartition(train$Cover_Type, p=0.2, list=FALSE)
model.rf2 <- train(Cover_Type~., data=train[small.train2, -1], method="rf")
predict.rf2 <- predict(model.rf2, newdata=test[, -1])
write.csv(cbind(Id=test[1], Cover_Type=predict.rf2), "submission03_rf.csv", row.names=FALSE)
cars
pressure
library(knitr)
library(ggplot2)
library(reshape2)
library(dplyr)
library(caret)
library(randomForest)
setwd("C:/Users/Fan/R/Kaggle/Forest Cover Type Prediction")
options(stringsAsFactors=FALSE)
setwd("C:/Users/Fan/R/DataSci/08. Practical Machine Learning/CourseProject_PML/Practical_Machine_Learning_Course_Project")
setwd("C:/Users/Fan/R/DataSci/08. Practical Machine Learning/CourseProject_PML/Practical_Machine_Learning_Course_Project")
setwd("C:/Users/Fan/R/DataSci/08. Practical Machine Learning/CourseProject_PML/Practical_Machine_Learning_Course_Project")
options(stringsAsFactors=FALSE)
pml_testing <- read.csv("pml-testing.csv")
str(pml_testing)
pml_training <- read.csv("pml-training.csv")
str(pml_training)
apply(pml_training, 2, function(x) sum(is.na(x)))
no.na <- colSums(is.na(rbind(pml_training, pml_testing)))
?colSums
a <- rbind(pml_training, pml_testing)
str(pml_testing)
no.na <- colSums(is.na(rbind(pml_training[,-ncol(pml_training)], pml_testing[,-ncol(pml_testing)])))
no.na
no.na <- colSums(is.na(rbind(pml_training[,-ncol(pml_training)], pml_testing[,-ncol(pml_testing)]))) == 0
no.na
sum(no.na)/length(no.na)
in.train <- createDataPartition(pml_training$classe, p=0.7, list=FALSE)
train <- pml_training[in.train, ]
test <- pml_training[-in.train, ]
?read.csv
pml_training <- read.csv("pml-training.csv", row.names=1)
str(pml_training)
pml_testing <- read.csv("pml-testing.csv", row.names=1)
no.na <- colSums(is.na(rbind(pml_training[,-ncol(pml_training)], pml_testing[,-ncol(pml_testing)]))) == 0
set.seed(123)  # Set seed for reproducibility
in.train <- createDataPartition(pml_training$classe, p=0.7, list=FALSE)
train <- pml_training[in.train, no.na]
test <- pml_training[-in.train, no.na]
str(train)
train <- pml_training[in.train, no.na][, -1:6]
train <- pml_training[in.train, no.na][, -(1:6)]
str(train)
pml_training$classe <- as.factor(pml_training$classe)
no.na <- colSums(is.na(rbind(pml_training[,-ncol(pml_training)], pml_testing[,-ncol(pml_testing)]))) == 0
# Create train/test data
set.seed(123)  # Set seed for reproducibility
in.train <- createDataPartition(pml_training$classe, p=0.7, list=FALSE)
train <- pml_training[in.train, no.na][, -(1:6)]
test <- pml_training[-in.train, no.na][, -(1:6)]
str(train)
model.rf <- train(classe~., data=train, method="rf")
training <- pml_training[, no.na][, -(1:6)]
training <- filter(training, gyros_dumbbell_x>-20,
gyros_dumbbell_y < 10,
gyros_dumbbell_z < 50,
magnet_dumbbell_y > -1000,
gyros_forearm_x > -10,
gyros_forearm_y < 50,
gyros_forearm_z < 50)
for(i in 1:52){
plot(training[, i], training[, 53], main=i)
}
i <- 52
plot(training[, i], training[, 53], main=i)
plot(training[, i], training[, 53], main=i, alpha=0.2)
?plot
qplot(training[, i], training[, 53])
qplot(training[, i], training[, 53], alpha=0.2)
qplot(training[, i], training[, 53], alpha=0.1)
in.train <- createDataPartition(training$classe, p=0.05, list=FALSE)
train <- pml_training[in.train, no.na][, -(1:6)]
test <- pml_training[-in.train, no.na][, -(1:6)]
model.rf <- train(classe~., data=train, method="rf")
model.rf <- train(classe~., data=train[, 40:53], method="rf")
predict.rf <- predict(model.rf, newdata=test)
predict.rf
confusionMatrix(predict.rf, test[, 53])
for(i in 1:12){
ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1)
}
for(i in 1:12){
a <- ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1)
print(a)
}
?ggsave
ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1) +
geom_smooth(method="lm", se=FALSE)
for(i in 1:12){
ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1) +
geom_smooth(method="lm", se=FALSE)
print(paste0("../", i, colnames(training)[i], ".png"))
}
for(i in 1:12){
ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1) +
geom_smooth(method="lm", se=FALSE)
ggsave(paste0("../", i, colnames(training)[i], ".png"))
}
pml_training <- read.csv("pml-training.csv", row.names=1)
pml_testing <- read.csv("pml-testing.csv", row.names=1)
#pml_training$classe <- as.factor(pml_training$classe)
no.na <- colSums(is.na(rbind(pml_training[,-ncol(pml_training)], pml_testing[,-ncol(pml_testing)]))) == 0
training <- pml_training[, no.na][, -(1:6)]
training <- filter(training, gyros_dumbbell_x>-20,
gyros_dumbbell_y < 10,
gyros_dumbbell_z < 50,
magnet_dumbbell_y > -1000,
gyros_forearm_x > -10,
gyros_forearm_y < 50,
gyros_forearm_z < 50)
for(i in 1:52){
ggplot(training, aes_string(x=colnames(training)[i], y=colnames(training)[53])) +
geom_point(alpha=0.1) +
geom_smooth(method="lm", se=FALSE)
ggsave(paste0("../", i, colnames(training)[i], ".png"))
}
str(training)
library(GGally)
?ggpair
?ggpairs(training[49:53])
ggpairs(training[49:53])
b <- ggpairs(training[49:53])
ggsave("../abc.png", b)
?ggpairs
?pdf
pdf("../abc.pdf", b)
pdf("../abc.pdf", 11, 8, b)
pdf("../abc.pdf", width=11, height=8)
ggpairs(training[49:53])
device.off()
dev.off()
str(training)
pdf("../1_4.pdf", width=10, height=7)
ggpairs(training[c(1:4, 53)])
dev.off()
colnames(training)
pdf("../5_7.pdf", width=10, height=7)
ggpairs(training[c(5:7, 53)])
dev.off()
pdf("../8_10.pdf", width=10, height=7)
ggpairs(training[c(8:10, 53)])
dev.off()
pdf("../11_13.pdf", width=10, height=7)
ggpairs(training[c(11:13, 53)])
dev.off()
colnames(training)
pdf("../14_17.pdf", width=10, height=7)
ggpairs(training[c(14:17, 53)])
dev.off()
pdf("../18_20.pdf", width=10, height=7)
ggpairs(training[c(18:20, 53)])
dev.off()
pdf("../21_23.pdf", width=10, height=7)
ggpairs(training[c(21:23, 53)])
dev.off()
pdf("../24_26.pdf", width=10, height=7)
ggpairs(training[c(24:26, 53)])
dev.off()
pdf("../27_30.pdf", width=10, height=7)
ggpairs(training[c(27:30, 53)])
dev.off()
pdf("../31_33.pdf", width=10, height=7)
ggpairs(training[c(31:33, 53)])
dev.off()
pdf("../34_36.pdf", width=10, height=7)
ggpairs(training[c(34:36, 53)])
dev.off()
colnames(training)
pdf("../37_39.pdf", width=10, height=7)
ggpairs(training[c(37:39, 53)])
dev.off()
pdf("../40_43.pdf", width=10, height=7)
ggpairs(training[c(40:43, 53)])
dev.off()
pdf("../44_46.pdf", width=10, height=7)
ggpairs(training[c(44:46, 53)])
dev.off()
pdf("../47_49.pdf", width=10, height=7)
ggpairs(training[c(47:49, 53)])
dev.off()
pdf("../50_52.pdf", width=10, height=7)
ggpairs(training[c(50:52, 53)])
dev.off()
ggplot(melt(training, id="classe"), aes(x=value, group=classe)) +
geom_bar() +
facet_wrap(~variable, ncol=3)
ggplot(melt(training, id="classe"), aes(x=value, group=classe)) +
geom_boxplot() +
facet_wrap(~variable, ncol=3)
ggplot(melt(training, id="classe"), aes(x=value, y=classe)) +
geom_boxplot() +
facet_wrap(~variable, ncol=3)
ggplot(melt(training, id="classe"), aes(x=classe, y=value)) +
geom_boxplot() +
facet_wrap(~variable, ncol=3)
?ggsave
ggsave("boxplot.pdf", width=5, height=20)
# Load mtcars data into a tbl_df object
car.tbl <- tbl_df(mtcars)
car.tbl$Transmission <- as.factor(ifelse(car.tbl$am==1, "Manual", "Automatic"))
# the displacement is roughly uniform distribution.
car.auto <- filter(car.tbl, Transmission=="Automatic")
car.manual <- filter(car.tbl, Transmission=="Manual")
library(knitr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(dplyr)
data(mtcars)
opts_knit$set(message = FALSE, echo=FALSE, fig.width = 6, fig.height = 2)
options(stringsAsFactors=FALSE)
ggpairs(mtcars)
lm.3 <- lm(mpg~gear, data=car.tbl)
summary(lm.3)
lm.4 <- lm(mpg~wt+qsec+cyl+gear, data=car.tbl)
summary(lm.4)
lm.4 <- lm(mpg~wt+cyl+gear, data=car.tbl)
summary(lm.4)
lm.5 <- lm(mpg~.Transmission, data=car.tbl)
lm.5 <- lm(mpg~.Transmission, data=car.tbl)
car.tbl
lm.5 <- lm(mpg~.-Transmission, data=car.tbl)
summary(lm.5)
lm.5 <- lm(mpg~wt+cyl+gear+Transmission, data=car.tbl)
summary(lm.5)
lm.5 <- lm(mpg~wt+cyl+gear+Transmission*cyl, data=car.tbl)
summary(lm.5)
lm.5 <- lm(mpg~wt+cyl+gear+Transmission, data=car.tbl)
summary(lm.5)
lm.4 <- lm(mpg~wt+cyl+gear, data=car.tbl)
summary(lm.4)
lm.5 <- lm(mpg~wt+cyl+gear+Transmission, data=car.tbl)
summary(lm.5)
